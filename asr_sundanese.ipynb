{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oyVcQpE7ewEO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrXUquVa-Gr6"
   },
   "outputs": [],
   "source": [
    "wavs_path = \"data/wavs/tmp/asr_sundanese/wavs/\"\n",
    "metadata_path = \"data/utt_spk_text.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dH0jDdsF38JQ",
    "outputId": "5657c761-71fc-4e69-9cfa-0bf3ea85d0ec"
   },
   "outputs": [],
   "source": [
    "labels = os.listdir(wavs_path)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "j-4GpECi-KBW",
    "outputId": "0e7e86dc-13de-4e78-bfea-60e5242124a4"
   },
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_path, sep=\"\\t\", header=None, quoting=3)\n",
    "metadata_df = metadata_df[:len(labels)]\n",
    "metadata_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3GX2jd3-KjS"
   },
   "outputs": [],
   "source": [
    "metadata_df.columns = [\"file_id\", \"user_id\", \"transcription\"]\n",
    "metadata_df = metadata_df[[\"file_id\", \"transcription\"]]\n",
    "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChDiFsLOFEBV",
    "outputId": "d8b94a57-061d-4b6e-f6b1-c8cbd5b24b0e"
   },
   "outputs": [],
   "source": [
    "split = int(len(metadata_df) * 0.95)\n",
    "df_train = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "\n",
    "print(f\"Size of the training set: {len(df_train)}\")\n",
    "print(f\"Size of the validation set: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSs7NHjyFtSk",
    "outputId": "51b2bf2e-3d4e-424f-d468-dd9b2f7c570d"
   },
   "outputs": [],
   "source": [
    "# The set of characters accepted in the transcription\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "\n",
    "# Mapping characters to integers\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "                    vocabulary=char_to_num.get_vocabulary(),\n",
    "                    oov_token=\"\",\n",
    "                    invert=True)\n",
    "\n",
    "print(f\"The vocabulary is: {char_to_num.get_vocabulary()}\")\n",
    "print(f\"Size: {char_to_num.vocabulary_size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ4xNu5qbEYw"
   },
   "source": [
    "## Process the audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiZ0RBqMGGnl"
   },
   "outputs": [],
   "source": [
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "    # Read wav file\n",
    "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
    "    \n",
    "    # Decode the wav file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    \n",
    "    # Change type to float\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    \n",
    "    # Get the spectogram\n",
    "    spectogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "    \n",
    "    # Only need the magnitude\n",
    "    spectogram = tf.abs(spectogram)\n",
    "    spectogram = tf.math.pow(spectogram, 0.5)\n",
    "    \n",
    "    # Normalization\n",
    "    means = tf.math.reduce_mean(spectogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectogram, 1, keepdims=True)\n",
    "    spectogram = (spectogram - means) / (stddevs + 1e-10)\n",
    "    \n",
    "    # Convert the label to lower case\n",
    "    label = tf.strings.lower(label)\n",
    "    \n",
    "    # Split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "    \n",
    "    # Map the characters in label to number\n",
    "    label = char_to_num(label)\n",
    "    \n",
    "    return spectogram, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ARUcErcebb-p"
   },
   "source": [
    "## Creating dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiupcWvpGUJc"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Define the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"file_id\"]), list(df_train[\"transcription\"]))\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"file_id\"]), list(df_val[\"transcription\"]))\n",
    ")\n",
    "\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k6PdkQ3Ybmcu"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "B5satA3aGnZW",
    "outputId": "0d6adef6-35ea-49bc-9ade-17b253ee701b"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "for batch in train_dataset.take(1):\n",
    "    spectogram = batch[0][0].numpy()\n",
    "    spectogram = np.array([np.trim_zeros(x) for x in np.transpose(spectogram)])\n",
    "    label = batch[1][0]\n",
    "    \n",
    "    # Spectogram\n",
    "    label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    ax.imshow(spectogram, vmax=1)\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # Wav\n",
    "    file = tf.io.read_file(wavs_path + list(df_train[\"file_id\"])[0] + \".wav\")\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = audio.numpy()\n",
    "    ax = plt.subplot(2, 1, 1)\n",
    "    plt.plot(audio)\n",
    "    ax.set_title(\"Signal Wave\")\n",
    "    ax.set_xlim(0, len(audio))\n",
    "    display.display(display.Audio(np.transpose(audio), rate=16000))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KQK7yy1wbyZ9"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZcd15gWG8T1"
   },
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "    \n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    \n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2vnQVHFhbsBt"
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWQr6qu_G_kM"
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
    "    # Models input\n",
    "    input_spectogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    \n",
    "    # Expand the dimension to use 2D CNN\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectogram)\n",
    "    \n",
    "    # Convolution layer 1\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 41],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "        )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "    \n",
    "    # Convolution layer 2\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 21],\n",
    "        strides=[1, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "        )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    \n",
    "    # Reshape the resulted volume to feed the RNNs layers\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "    \n",
    "    # RNN layers\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "        \n",
    "    # Dense layer\n",
    "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
    "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    # Classification layer\n",
    "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Model\n",
    "    model = keras.Model(input_spectogram, output, name=\"DeepSpeech_2\")\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    \n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBKqpXqtHFrv",
    "outputId": "ac4374bf-b98e-4137-9ff2-cbde6c02c06b"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    input_dim=fft_length // 2 + 1,\n",
    "    output_dim=char_to_num.vocabulary_size(),\n",
    "    rnn_units=512,\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D71MVLGob3np"
   },
   "source": [
    "## Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCw8tUvi-wmq"
   },
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acoWmvid_a0z"
   },
   "outputs": [],
   "source": [
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target: {targets[i]}\")\n",
    "            print(f\"Predictions: {predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZQHYzHX-5b7",
    "outputId": "0d2735a4-fc7f-400e-9d59-64aaa9daa9cf"
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[validation_callback],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KyWT2toCb63j"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0ggeQK__xI_"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "for batch in validation_dataset:\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "wer_score = wer(targets, predictions)\n",
    "print(\"-\" * 100)\n",
    "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "print(\"-\" * 100)\n",
    "for i in np.random.randint(0, len(predictions), 2):\n",
    "    print(f\"Target: {targets[i]}\")\n",
    "    print(f\"Predictions: {predictions[i]}\")\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
